"""
Consumers for the background task queues. Note that these must run in a separate
thread than the main background tasks to avoid blocking during long-running
synchronous communication. There are two main tasks:

- ConsumeQueue, that takes the queue generated by send_clone and sends off the
  batched transfers.
- CheckConsumedQueue, that looks at completed tasks from ConsumeQueue and
  programatically checks whether their transfers have successfuly 'gone through'.
"""

import datetime
import time
from pathlib import Path
from typing import TYPE_CHECKING, Callable

from loguru import logger
from sqlalchemy import func, select

from hera_librarian.exceptions import LibrarianError
from hera_librarian.transfer import TransferStatus
from librarian_server.database import get_session
from librarian_server.orm.librarian import Librarian
from librarian_server.orm.sendqueue import SendQueue
from librarian_server.settings import server_settings

from .task import Task

if TYPE_CHECKING:
    from sqlalchemy.orm import Session


class ConsumeQueue(Task):
    """
    A task that consumes the SendQueue, one by one, until it is drained
    or the time is up.
    """

    def core(self, session_maker):
        current_time = datetime.datetime.now(datetime.timezone.utc)
        timeout_after = current_time + (
            self.soft_timeout
            if self.soft_timeout is not None
            else datetime.timedelta(days=100)
        )

        while datetime.datetime.now(datetime.timezone.utc) <= timeout_after:
            # Controlled by retries.
            ret = consume_queue_item(session_maker=session_maker)

            if not ret:
                break

        return

    # pragma: no cover
    def on_call(self):
        self.core(session_maker=get_session)


class CheckConsumedQueue(Task):
    """
    A task that checks on consumed items to see if their transfers
    have completed already.
    """

    complete_status: TransferStatus = TransferStatus.STAGED
    "The status to set the completed items to. Leave this as default if you are doing typical inter-librarian transfers"

    def core(self, session_maker):
        current_time = datetime.datetime.now(datetime.timezone.utc)
        timeout_after = current_time + (
            self.soft_timeout
            if self.soft_timeout is not None
            else datetime.timedelta(days=100)
        )

        check_on_consumed(
            session_maker=session_maker,
            timeout_after=timeout_after,
            complete_status=self.complete_status,
        )
        return

    # pragma: no cover
    def on_call(self):
        self.core(session_maker=get_session)


def check_on_consumed(
    session_maker: Callable[[], "Session"],
    timeout_after: datetime.datetime,
    complete_status: TransferStatus = TransferStatus.STAGED,
) -> bool:
    """
    Check on the 'consumed' SendQueue items. Loop through everything with
    consumed = True, and ask to see if their transfers have gone through.

    There are three possible results:

    1. The transfer is still marked as INTIATED, which means that it is
       still ongoing. It is left as-is.
    2. The transfer is marked as COMPLETED. All downstream OutgoingTransfer
       objects will be updated to complete_status.
    3. The transfer is marked as FAILED. All downstream OutgoingTransfer
       objects will be updated to also have been failed.

    Parameters
    ----------

    session_maker: Callable[[], Session]
        A callable that returns a new session object.
    complete_status: TransferStatus
        The status to mark the transfer as if it is complete. By default, this
        is STAGED. All OutgoingTransfer objects will have their status' updated
        in this case.

    Returns
    -------

    status: bool
        If we return False, then there was nothing to consume. A return value of
        True indicates that we consmed an item.
    """

    with session_maker() as session:
        query_start = time.perf_counter()

        stmt = select(SendQueue).with_for_update(skip_locked=True)
        stmt = stmt.filter_by(consumed=True).filter_by(completed=False)
        queue_items = session.execute(stmt).scalars().all()

        query_end = time.perf_counter()

        logger.info(
            "Queried database for {} consumed items in {} seconds",
            len(queue_items),
            query_end - query_start,
        )

        if len(queue_items) == 0:
            return False

        for queue_item in queue_items:
            if datetime.datetime.now(datetime.timezone.utc) > timeout_after:
                # We are out of time.
                return False

            # Check if the librarian is enabled.
            librarian = (
                session.query(Librarian)
                .filter_by(name=queue_item.destination)
                .one_or_none()
            )

            if librarian is None or not librarian.transfers_enabled:
                # We can't do anything with this librarian, but there may be other
                # librarians that are enabled.
                continue

            logger.info(
                "Handling queue item {q.id} with {q.retries} retries", q=queue_item
            )

            current_status = queue_item.async_transfer_manager.transfer_status(
                settings=server_settings
            )

            if current_status == TransferStatus.INITIATED:
                logger.info("Transfer for {q.id} is still ongoing", q=queue_item)
                continue
            elif current_status == TransferStatus.COMPLETED:
                if complete_status == TransferStatus.STAGED:
                    logger.info("Transfer for {q.id} is staged", q=queue_item)
                    try:
                        queue_item.update_transfer_status(
                            new_status=complete_status,
                            session=session,
                        )
                    except LibrarianError as e:
                        logger.info(
                            "Librarian {q.destination} was not available for contact, "
                            "returning error {e}, trying again later",
                            q=queue_item,
                            e=e,
                        )

                        continue
                    except AttributeError as e:
                        # This is a larger problem; we are missing the associated
                        # librarian in the database. Better ping!
                        logger.info(
                            "Librarian {q.destination} was not found in the database, "
                            "returning error {e}, trying again later, but likely this requires "
                            "manual remedy",
                            q=queue_item,
                            e=e,
                        )

                        continue
                else:
                    raise ValueError(
                        "No other status than STAGED is supported for checking on consumed"
                    )
            elif current_status == TransferStatus.FAILED:
                logger.info("Transfer for {q.id} has failed", q=queue_item)
                for transfer in queue_item.transfers:
                    transfer.fail_transfer(session=session, commit=False)
            else:
                logger.error(
                    "Incompatible return value for transfer status from "
                    "SendQueue item {queue_item.id} ({current_status})",
                    queue_item=queue_item,
                    current_status=current_status,
                )
                continue

            # If we got down here, we can mark the transfer as consumed.
            logger.info("Marking {q.id} as completed", q=queue_item)
            queue_item.completed = True
            queue_item.completed_time = datetime.datetime.now(datetime.timezone.utc)

            session.commit()

    return True


def consume_queue_item(session_maker: Callable[[], "Session"]) -> bool:
    """
    Consume the current, oldest, and highest priority item.

    If we return False, then there was nothing to consume. A return value of
    True indicates that we consmed an item.
    """

    with session_maker() as session:
        query_start = time.perf_counter()
        stmt = select(SendQueue).with_for_update(skip_locked=True)
        stmt = stmt.filter_by(completed=False).filter_by(consumed=False)
        stmt = stmt.order_by(SendQueue.priority.desc(), SendQueue.created_time)
        queue_item = session.execute(stmt).scalar()
        query_end = time.perf_counter()

        logger.info(
            "Queried database for next queue item in {} seconds",
            query_end - query_start,
        )

        if queue_item is None:
            logger.info("Found no new queue item, returning")
            # Nothing to do!
            return False

        # Check if the librarian is enabled.
        librarian = (
            session.query(Librarian)
            .filter_by(name=queue_item.destination)
            .one_or_none()
        )

        if librarian is None or not librarian.transfers_enabled:
            # We can't do anything with this librarian, but there may be other
            # librarians that are enabled.
            return True

        # Now, check we don't have too much going on.
        query_start = time.perf_counter()
        stmt = (
            select(func.count(SendQueue.id))
            .filter_by(consumed=True)
            .filter_by(completed=False)
        )
        in_flight = session.execute(stmt).scalar()
        query_end = time.perf_counter()

        logger.info(
            "Queried database for in-flight items in {} seconds",
            query_end - query_start,
        )

        if in_flight > server_settings.max_async_inflight_transfers:
            logger.info("Too many in-flight items, returning")
            # Too much to do!
            return False

        # Otherwise, we are free to consume this item.
        transfer_list = [
            (Path(x.source_path), Path(x.dest_path)) for x in queue_item.transfers
        ]
        logger.info(
            "Consuming queue item {q.id} ({n} transfers)",
            q=queue_item,
            n=len(transfer_list),
        )
        # Need to create a copy here in case there is an internal state
        # change. Otherwise SQLAlchemy won't write it back.
        transfer_manager = queue_item.async_transfer_manager.model_copy()
        success = transfer_manager.batch_transfer(
            transfer_list, settings=server_settings
        )

        if success:
            queue_item.consumed = True
            queue_item.consumed_time = datetime.datetime.now(datetime.timezone.utc)

            # Be careful, the internal state of the async transfer manager
            # may have changed. Send it back.
            queue_item.async_transfer_manager = transfer_manager

            logger.info("Successfully consumed queue item {q.id}", q=queue_item)
        else:
            queue_item.retries += 1
            logger.warning(
                "Failed to consume queue item {q.id} ({r}/{m_r} retries)",
                q=queue_item,
                r=queue_item.retries,
                m_r=server_settings.max_async_send_retries,
            )

            if queue_item.retries > server_settings.max_async_send_retries:
                logger.error(
                    "Queue item {q.id} has exceeded maximum retries, failing",
                    q=queue_item,
                )
                queue_item.fail(session=session)

        session.commit()

    return True
